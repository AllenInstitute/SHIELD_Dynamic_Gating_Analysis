{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f18dbc-a755-4340-a7a3-71b57b837c65",
   "metadata": {},
   "source": [
    "# LFP Analysis\n",
    "\n",
    "This notebook will demonstrate how to access and analyze LFP data from the Dynamic Gating dataset. LFP, which stands for \"local field potential,\" contains information about low-frequency (0.1-500 Hz) voltage fluctations around each recording site. It's complementary to the spiking activity, and can be analyzed on its own or in conjunction with spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413612bd-e657-4857-8b09-c97f651c0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynwb\n",
    "from allensdk.brain_observatory.ecephys.dynamic_gating_ecephys_session import DynamicGatingEcephysSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c661045-2a07-44fe-b1a8-d6fe385b9abb",
   "metadata": {},
   "source": [
    "The LFP data is in a seperate nwb to speed up processing since the LFP data is quite large. To access LFP, follow the steps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 'sub-608671_ses-20220518T214848.nwb'\n",
    "\n",
    "nwb_file_asset = pynwb.NWBHDF5IO(f'../data/sub-608671/{session}', mode='r', load_namespaces=True)\n",
    "nwb_file = nwb_file_asset.read()\n",
    "dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35271f3-8337-4441-a6d2-e103b4c69597",
   "metadata": {},
   "source": [
    "The probes data below shows the ids for this session. Note the lfp portion is empty since we have not loaded any LFP yet. This is done on the fly to speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7035a5-bfe8-4668-8d52-c74e78f2706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_gating_session.probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a64cc",
   "metadata": {},
   "source": [
    "Now lets load the LFP using a mapping of probe name to the corresponding LFP NWB. Use the probe id to find the corresponding LFP for this session. We provide a mapping of probe name to the corresponding LFP file identified by probe id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE TO CORRESPONDING PATH\n",
    "probe_map = {\n",
    "    'probeA': '../data/sub-608671/sub-608671_ses-None_probe-29_ecephys.nwb',\n",
    "    'probeB': '../data/sub-608671/sub-608671_ses-None_probe-30_ecephys.nwb',\n",
    "    'probeC': '../data/sub-608671/sub-608671_ses-None_probe-31_ecephys.nwb',\n",
    "    'probeD': '../data/sub-608671/sub-608671_ses-None_probe-32_ecephys.nwb',\n",
    "    'probeE': '../data/sub-608671/sub-608671_ses-None_probe-33_ecephys.nwb',\n",
    "    'probeF': '../data/sub-608671/sub-608671_ses-None_probe-34_ecephys.nwb'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ab0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load in with lfp map\n",
    "dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file, probe_data_path_map=probe_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deeea71-ebd3-4d01-9b55-08e46612a6a1",
   "metadata": {},
   "source": [
    "Now lets look at the lfp for a probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fda51-89c6-4755-8fbb-cab9e035842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp = dynamic_gating_session.get_lfp(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00694d7f-0c3b-4e21-be08-947ef5fae833",
   "metadata": {},
   "source": [
    "If we look at the probes table now, the lfp information is there after loading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca7b78-2435-4c1e-8346-5659d16dcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_gating_session.probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eebb00-8a6b-4589-afd3-3d85a5532215",
   "metadata": {},
   "source": [
    "Lets take a look at the contents of the lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3777c3-1c7b-4e68-8f09-578cf63dc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df09cb6-3a53-460c-b635-759133cc0da5",
   "metadata": {},
   "source": [
    "The LFP data is stored as an xarray.DataArray object, with coordinates of time and channel. The xarray library simplifies the process of working with N-dimensional data arrays, by keeping track of the meaning of each axis. If this is your first time encountering xarrays, we strongly recommend reading through the documentation before going further. Getting used to xarrays can be frustrating, especially when they don't behave like numpy arrays. But they are designed to prevent common mistakes when analyzing multidimensional arrays, so they are well worth learning more about. Plus, the syntax is modeled on that of the pandas library, so if you're familiar with that you already have a head start.\n",
    "\n",
    "Let's use the DataArray.sel() method to select a slice through this array between 100 and 101 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6303ad4-517d-4289-a21c-3d2e8cfdad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_slice = lfp.sel(time=slice(100, 101))\n",
    "\n",
    "lfp_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec439f08-f2fd-49b3-8333-23b041ac360e",
   "metadata": {},
   "source": [
    "We see that this new DataArray is smaller than before; it contains the same number of channels, but only 1250 samples, due to the LFP sample rate of ~1250 Hz.\n",
    "\n",
    "Let's plot the data for one of the channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fc020-1107-4899-8d6a-ef88802e0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "_ = plt.plot(lfp_slice.time, lfp_slice.sel(channel=lfp_slice.channel[10]))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('LFP (V)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa1d69-cc70-41e3-bde3-60cc202b6ea5",
   "metadata": {},
   "source": [
    "Alternatively, we can visualize this slice of data using matplotlib's imshow method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510d1fc-4472-47da-8170-ebd724c9c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "im = plt.imshow(lfp_slice.T,aspect='auto',origin='lower',vmin=-1e-3, vmax=1e-3)\n",
    "_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n",
    "_ = plt.xlabel('Sample number')\n",
    "_ = plt.ylabel('Channel index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e06bcc-cc56-41ac-b092-20f0c0726379",
   "metadata": {},
   "source": [
    "Note that we've transposed the original array to place the time dimension along the x-axis. We've also configured the plot so that the origin of the array is in the lower-left, so that that channels closer to the probe tip are lower in the image.\n",
    "\n",
    "A few things to note about this plot:\n",
    "* The units of the LFP are volts, so the color scale ranges from -1 to +1 mV\n",
    "* Even though there are 384 channels on the Neuropixels probe, there are only 96 channels in this plot. That's because only every 4th channel is included in the NWB file (resulting in 40 micron vertical spacing). In addition, the reference channels and channels far outside the brain have been removed.\n",
    "* The top of the plot is relatively flat. This corresponds to channels that are outside the brain. The LFP channels are originally referenced to the tip reference site on the Neuropixels probe. Before NWB packaging, the LFP data is digitally referenced to the channels outside the brain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffdc9e-4989-41ac-aef2-5652b7d5eceb",
   "metadata": {},
   "source": [
    "# Aliging LFP Data to Stimulus\n",
    "\n",
    "In the above example, we selected LFP data based on an arbitrary time span (100 to 101 seconds). For many analyses, however, you'll want to align the data to the onset of a particular type of stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820235e-1485-4bc4-94a9-3787bbc68127",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_presentations = dynamic_gating_session.stimulus_presentations\n",
    "flashes = stim_presentations[stim_presentations['stimulus_name'].str.contains('flash')]\n",
    "presentation_times = flashes.start_time.values\n",
    "presentation_ids = flashes.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a96cf2-c700-49e9-be5b-7c303204857b",
   "metadata": {},
   "source": [
    "First, let's make a convenience function that helps us align the LFP to times of interest. Because we're using xarrays, the alignment operation is fast, and doesn't require any for loops! There's a lot going on here, so we recommend referring to the pandas and xarray documentation if anything is confusing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8379b-e3a7-41f9-b77f-835a97aa1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_lfp(lfp, trial_window, alignment_times, trial_ids = None):\n",
    "    '''\n",
    "    Aligns the LFP data array to experiment times of interest\n",
    "    INPUTS:\n",
    "        lfp: data array containing LFP data for one probe insertion\n",
    "        trial_window: vector specifying the time points to excise around each alignment time\n",
    "        alignment_times: experiment times around which to excise data\n",
    "        trial_ids: indices in the session stim table specifying which stimuli to use for alignment.\n",
    "                    None if aligning to non-stimulus times\n",
    "    \n",
    "    OUTPUT:\n",
    "        aligned data array with dimensions channels x trials x time\n",
    "    '''\n",
    "    \n",
    "    time_selection = np.concatenate([trial_window + t for t in alignment_times])\n",
    "    \n",
    "    if trial_ids is None:\n",
    "        trial_ids = np.arange(len(alignment_times))\n",
    "        \n",
    "    inds = pd.MultiIndex.from_product((trial_ids, trial_window), \n",
    "                                      names=('presentation_id', 'time_from_presentation_onset'))\n",
    "\n",
    "    ds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n",
    "    ds = ds.assign(time=inds).unstack('time')\n",
    "\n",
    "    return ds['aligned_lfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885e4c4-a1ff-4e8c-807c-cc06ba43a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_lfp = align_lfp(lfp, np.arange(-0.5, 0.5, 1/500), presentation_times, presentation_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786646d2-6e73-48f3-89d9-b007ab0cffbc",
   "metadata": {},
   "source": [
    "aligned_lfp is a DataArray with dimensions of channels x trials x time. It's been downsampled to 500 Hz by changing the time step in the trial_window argument of the align_lfp function.\n",
    "\n",
    "Note that we can get the channels IDs for each channel in this DataArray. Let's use the session channels table to map these to the probe and mark the surface of the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe17378-1b89-467e-a873-78f04d8e2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chans = dynamic_gating_session.get_channels()\n",
    "lfp_chan_depths = [chans.loc[c]['probe_vertical_position'] for c in lfp.channel.values]\n",
    "\n",
    "chans_in_brain = chans[(chans['probe_id']==42)&(~chans['structure_acronym'].str.contains('No Area'))&(~chans['structure_acronym'].str.contains('out of brain'))]\n",
    "first_channel_in_brain_position = chans_in_brain['probe_vertical_position'].max()\n",
    "first_channel_in_brain_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a45959-1bbd-4c34-b48f-6fa7a03ba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Flash aligned mean LFP')\n",
    "im = ax.pcolor(aligned_lfp.time_from_presentation_onset.values, lfp_chan_depths, aligned_lfp.mean(dim='presentation_id').data)\n",
    "_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n",
    "_ = plt.xlabel('Time from flash onset (s)')\n",
    "_ = plt.ylabel('Channel Position from Tip (um)')\n",
    "\n",
    "ax.axvline(0, c='w', ls='dotted')\n",
    "ax.axvline(0.25, c='w', ls='dotted')\n",
    "ax.axhline(first_channel_in_brain_position, c='w')\n",
    "ax.text(-0.4, first_channel_in_brain_position+50, 'brain surface', c='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1f93d-8278-43db-bef6-a5ab3d8f4dec",
   "metadata": {},
   "source": [
    "# Aligning LFP data to units\n",
    "\n",
    "The previous section demonstrated how to align the LFP in time. What if we want to extract the LFP at a particular location in space, corresponding to the location of a unit we're analyzing?\n",
    "\n",
    "Let's start by finding a well-isolated unit whose peak channel is included in our LFP data.\n",
    "\n",
    "Once we've selected a unit of interest, we can align the LFP data to its spike times:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c835179-ed94-43e6-8605-156bad539609",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_units  = dynamic_gating_session.get_units()\n",
    "\n",
    "#Grab units whose peak channels are in the LFP data, have relatively low isi violations and high amplitude spikes\n",
    "units_on_lfp_chans = sess_units[(sess_units.peak_channel_id.isin(lfp.channel.values)) &\n",
    "                                (sess_units.isi_violations < 0.5) &\n",
    "                                (sess_units.amplitude > 200)]\n",
    "\n",
    "#Merge this curated unit table with the channel table to get CCF locations for these units\n",
    "units_on_lfp_chans = units_on_lfp_chans.merge(chans, left_on='peak_channel_id', right_index=True)\n",
    "units_on_lfp_chans.structure_acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6b889-aeeb-42e9-88ab-2ef0d7dc81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a unit\n",
    "area_units = units_on_lfp_chans[units_on_lfp_chans.structure_acronym.str.contains('VISp')]\n",
    "unit_id = area_units.index.values[5]\n",
    "\n",
    "#Get the peak channel ID for this unit (the channel on which it had the greatest spike amplitude)\n",
    "peak_chan_id = units_on_lfp_chans.loc[unit_id]['peak_channel_id']\n",
    "peak_probe_position = units_on_lfp_chans.loc[unit_id]['probe_vertical_position']\n",
    "\n",
    "area_units.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7294be-3a51-49db-8029-11cbda6ce8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 1920\n",
    "end_time = 1930\n",
    "\n",
    "spike_times = dynamic_gating_session.spike_times[unit_id]\n",
    "\n",
    "times_in_range = spike_times[(spike_times > start_time) & (spike_times < end_time)]\n",
    "\n",
    "lfp_data = lfp.sel(time = slice(start_time, end_time))\n",
    "lfp_data = lfp_data.sel(channel = peak_chan_id, method='nearest')\n",
    "\n",
    "dynamic_gating_session.spike_times[unit_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff44dd-6a8f-483b-9132-bd58e051c97b",
   "metadata": {},
   "source": [
    "Let's also find the stimulus presentations in this window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f8817-158c-43b7-bd1e-f22b571314e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims_in_window = stim_presentations[(stim_presentations.start_time>start_time)&(stim_presentations.start_time<end_time) &\n",
    "                                    (stim_presentations.omitted==False)]\n",
    "stim_times_in_window = stims_in_window.start_time.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779188f-5bee-487e-bf6a-a0bd97c2abe7",
   "metadata": {},
   "source": [
    "Finally, we can plot the spike times and stim times along with the LFP for this interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853c618-670a-4c88-a3d6-868bfdb50542",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(lfp_data.time, lfp_data)\n",
    "_ = plt.plot(times_in_range, np.ones(times_in_range.shape)*3e-4, '.r')\n",
    "_ = plt.xlabel('Time (s)')\n",
    "_ = plt.ylabel('LFP (V)')\n",
    "\n",
    "_ = plt.plot(stim_times_in_window, np.ones(stim_times_in_window.size)*4e-4, 'vg')\n",
    "\n",
    "plt.legend(['LFP', 'spikes', 'stim times'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdf25d-1f11-4e5d-acce-875e7007061a",
   "metadata": {},
   "source": [
    "Now let's calculate a spike triggered average of the LFP using a subset of spikes for our unit of interest and the align_lfp function we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d0477-3207-4d37-8590-d2eb06d9d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42) #set seed for deterministic results\n",
    "spikes_to_use = rng.choice(spike_times, min((spike_times.size, 1000)), replace=False)\n",
    "spike_triggered_lfp = align_lfp(lfp, np.arange(-0.1, 0.1, 1/1250), spikes_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5f420-01e0-4dd6-b77f-e303bca0536f",
   "metadata": {},
   "source": [
    "Let's plot this spike-triggered LFP for a region of the probe centered on this unit's peak channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e623be-c41c-4e6e-9bbd-13b8af8791c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(spike_triggered_lfp.time_from_presentation_onset.values, lfp_chan_depths, \n",
    "               spike_triggered_lfp.mean(dim='presentation_id').data, shading='auto')\n",
    "\n",
    "ax.plot(-0.01, peak_probe_position, '>w')\n",
    "ax.text(-0.015, peak_probe_position, 'peak channel', c='w', va='center', ha='right')\n",
    "ax.set_ylim([peak_probe_position-300, peak_probe_position+300])\n",
    "ax.set_xlabel('Time from spike (s)')\n",
    "ax.set_ylabel('Channel depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072fbd7-595c-44e8-a2e4-14a55ced0535",
   "metadata": {},
   "source": [
    "# Current Source Density\n",
    "\n",
    "LFP data is commonly used to generate current source density (CSD) plots, which show the location of current sources and sinks along the probe axis. CSD analysis benefits from high spatial resolution, since it involves taking the second spatial derivative of the data. Because of Neuropixels dense site spacing, these probes are optimal for computing the CSD. However, the LFP data available through the AllenSDK has been spatially downsampled prior to NWB packaging.\n",
    "\n",
    "To provide access to a high-resolution CSD plot, we've pre-computed the CSD in response to a flash stimulus for all probes with LFP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f9098-3c18-4790-9c30-78bd9fdd48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csd = dynamic_gating_session.get_current_source_density(42)\n",
    "csd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7748fe-7b4c-4b5a-99c2-9d5f398d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "_ = plt.figure(figsize=(10,10))\n",
    "\n",
    "filtered_csd = gaussian_filter(csd.data, sigma=(5,1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "_ = ax.pcolor(csd[\"time\"], csd[\"vertical_position\"], filtered_csd, vmin=-3e4, vmax=3e4)\n",
    "\n",
    "_ = ax.set_xlabel(\"time relative to stimulus onset (s)\")\n",
    "_ = ax.set_ylabel(\"vertical position (um)\")\n",
    "\n",
    "\n",
    "chans_in_v1 = chans[(chans['probe_id']==42)&(chans['structure_acronym'].str.contains('VISp'))]\n",
    "last_cortex_channel_position = chans_in_v1['probe_vertical_position'].min()\n",
    "\n",
    "ax.axhline(first_channel_in_brain_position, c='w')\n",
    "ax.text(-0.075, first_channel_in_brain_position+50, 'brain surface', c='w')\n",
    "ax.axhline(last_cortex_channel_position, c='w')\n",
    "ax.text(-0.075, last_cortex_channel_position+50, 'end of cortex', c='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95782aa-c042-4d72-af6e-3ec4b15ebea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
