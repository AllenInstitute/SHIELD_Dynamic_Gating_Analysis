{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd49796-4e70-431e-b992-0cab59b5b89f",
   "metadata": {},
   "source": [
    "# Dynamic Gating Quickstart\n",
    "This notebook shows how to read an nwb for the dynamic gating experiment. The focus is on aligning neural data to visual and optotagging stimuli. This project shares many similarities with the Visual Behavior Neuropixels, so users are encouraged to check out the documentation for those for additional information and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754e28f5-be2d-4753-b60f-f5fbbf313798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynwb\n",
    "from allensdk.brain_observatory.ecephys.dynamic_gating_ecephys_session import DynamicGatingEcephysSession\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12a02a",
   "metadata": {},
   "source": [
    "# Metadata Tables\n",
    "\n",
    "Metadata tables have been provided for easy access to do analysis across sessions. Theses tables can be found under the metdata_tables folder in the repository. There are four tables\n",
    "\n",
    "* Sessions table: Contains relevant information on each session, such as areas hit, probes inserted and tracked, unit counts, etc.\n",
    "* Probes table: Contains metadata on all probes for all sessions in the dataset\n",
    "* Channels table: Contain metadata on electrodes on the probes. This includes coordinates for each channel in the Allen Common Coordinate Framework (CCF) and the CCF brain area\n",
    "* Units table: Contains all unit metrics from sorting for all sessions including firing rate, peak channel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3d49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_metadata_table = pd.read_csv(pathlib.Path('../metadata_tables/dynamic_gating_session_metadata.csv'))\n",
    "probes_table = pd.read_csv(pathlib.Path('../metadata_tables/probes_table.csv'))\n",
    "channels_table = pd.read_csv(pathlib.Path('../metadata_tables/channels_table.csv'))\n",
    "units_table = pd.read_csv(pathlib.Path('../metadata_tables/units_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out channels whose probes have not been traced to the ccf, channels out of the brain, and channels in white matter\n",
    "channels_table = channels_table[(channels_table['structure_acronym'] != 'out of brain') & (channels_table['structure_acronym'] != 'No Area') & \n",
    "                    (channels_table['structure_acronym'] != 'Track not annotated')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95763b0d-bca3-4d4d-90d9-642df671d820",
   "metadata": {},
   "source": [
    "# Read From NWB\n",
    "\n",
    "This section shows how to read a nwb file for a single session experiment. Find the session you want to look at, and just give the path to it as seen below. Then, we can use the SDK in a very similar manner to the Visual Behavior Neuropixels to access relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95cd2e-ad41-4daf-9557-e1ecdbcb22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 'sub-608671_ses-20220518T214848.nwb'\n",
    "# REPLACE WITH CORRESPONDING PATH\n",
    "nwb_file_asset = pynwb.NWBHDF5IO(f'../data/sub-608671/{session}', mode='r', load_namespaces=True)\n",
    "nwb_file = nwb_file_asset.read()\n",
    "dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3621e-7bdf-4d4e-9a3c-fb21ac489053",
   "metadata": {},
   "source": [
    "We can get a high-level summary of the session by accessing the metadata attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca852e8-586f-44ce-9014-fd2598cd3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_gating_session.metadata\n",
    "session_id = dynamic_gating_session.metadata['ecephys_session_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07e709-80eb-4b2b-b068-2ac71ec03812",
   "metadata": {},
   "source": [
    "We will now get the units and channels for this session. Then we will merge them to get the CCF areas and coordinates for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b266e4a-f12c-40c1-95aa-3e3f351d9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = dynamic_gating_session.get_units()\n",
    "units.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291cd40-2fe1-4b55-b480-0927bb2137c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = dynamic_gating_session.get_units()\n",
    "channels = dynamic_gating_session.get_channels()\n",
    "# filter out channels whose probes have not been traced to the ccf, channels out of the brain, and channels in white matter\n",
    "channels = channels[(channels['structure_acronym'] != 'out of brain') & (channels['structure_acronym'] != 'No Area') & \n",
    "                    (channels['structure_acronym'] != 'Track not annotated')]\n",
    "\n",
    "units_channels = units.merge(channels, left_on='peak_channel_id', right_index=True)\n",
    "units_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fba299-0b2e-46a7-b8ad-b0d0c2d735a9",
   "metadata": {},
   "source": [
    "Now we will look at the brain structures that were recorded during this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4044d-1ea6-4c05-b2de-35d5b2cbdab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_channels.value_counts('structure_acronym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c08e5a-883a-4abf-9b2c-ecb57970034d",
   "metadata": {},
   "source": [
    "# PSTH for image changes\n",
    "Next, we will grab spike times and calculate the change response for 'good' units. The filtering of the units will depend on the analysis done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb8b4f-d28e-4fd4-afd5-386ed5fc18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = dynamic_gating_session.spike_times\n",
    "\n",
    "#first let's sort our units by depth\n",
    "units_channels = units_channels.sort_values('probe_vertical_position', ascending=False)\n",
    "\n",
    "#now we'll filter them\n",
    "good_unit_filter = ((units_channels['snr']>1)&\n",
    "                    (units_channels['isi_violations']<1)&\n",
    "                    (units_channels['firing_rate']>0.1))\n",
    "\n",
    "good_units = units_channels.loc[good_unit_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcee40-ae4d-4ec7-9e95-ac1a90544417",
   "metadata": {},
   "source": [
    "We can get the times when the image changes occurred from the stimulus presentations table. For now, we'll only take the image changes shown during the active behavior block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c2fd7-fa5d-4bae-ba45-62ff354943e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = dynamic_gating_session.stimulus_presentations\n",
    "change_times = stimulus_presentations[stimulus_presentations['active']&\n",
    "                            stimulus_presentations['is_change']]['start_time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de54f7-d59d-4c1e-af46-8798577c0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convenience function to compute the PSTH\n",
    "def makePSTH(spikes, startTimes, windowDur, binSize=0.001):\n",
    "    bins = np.arange(0,windowDur+binSize,binSize)\n",
    "    counts = np.zeros(bins.size-1)\n",
    "    for i,start in enumerate(startTimes):\n",
    "        startInd = np.searchsorted(spikes, start)\n",
    "        endInd = np.searchsorted(spikes, start+windowDur)\n",
    "        counts = counts + np.histogram(spikes[startInd:endInd]-start, bins)[0]\n",
    "    \n",
    "    counts = counts/startTimes.size\n",
    "    return counts/binSize, bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355d422-a959-4f7b-9ba3-af4682ceaa0e",
   "metadata": {},
   "source": [
    "We'll include enough time in our plot to see three image responses: the pre-change image response, the change response and the post-change response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e574a-0fd1-404e-8503-77a9952b2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to look at response for any given area\n",
    "def get_area_response(area_of_interest:str, good_units:pd.DataFrame, spike_times:dict, time_before_change:float=1) -> tuple[np.ndarray, ...]:\n",
    "    #Here's where we loop through the units in our area of interest and compute their PSTHs\n",
    "    area_change_responses = []\n",
    "    area_units = good_units[good_units['structure_acronym'].str.contains(area_of_interest)]\n",
    "    duration = 2.5\n",
    "    for iu, unit in area_units.iterrows():\n",
    "        unit_spike_times = spike_times[iu]\n",
    "        unit_change_response, bins = makePSTH(unit_spike_times, \n",
    "                                              change_times-time_before_change, \n",
    "                                              duration, binSize=0.01)\n",
    "        area_change_responses.append(unit_change_response)\n",
    "    area_change_responses = np.array(area_change_responses)\n",
    "    \n",
    "    return area_change_responses, bins\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66bcdc-e1d0-4c04-8ab9-5475e99ea0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = 'VISp'\n",
    "time_before_change = 1\n",
    "area_change_responses, bins = get_area_response(area_of_interest, good_units, spike_times, time_before_change=time_before_change)\n",
    "\n",
    "#Plot the results\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches([12,4])\n",
    "\n",
    "clims = [np.percentile(area_change_responses, p) for p in (0.1,99.9)]\n",
    "im = ax[0].imshow(area_change_responses, clim=clims)\n",
    "ax[0].set_title('Active Change Responses for {}'.format(area_of_interest))\n",
    "ax[0].set_ylabel('Unit number, sorted by depth')\n",
    "ax[0].set_xlabel('Time from change (s)')\n",
    "ax[0].set_xticks(np.arange(0, bins.size-1, 20))\n",
    "_ = ax[0].set_xticklabels(np.round(bins[:-1:20]-time_before_change, 2))\n",
    "\n",
    "ax[1].plot(bins[:-1]-time_before_change, np.mean(area_change_responses, axis=0), 'k')\n",
    "ax[1].set_title('{} population active change response (n={})'\\\n",
    "                .format(area_of_interest, area_change_responses.shape[0]))\n",
    "ax[1].set_xlabel('Time from change (s)')\n",
    "ax[1].set_ylabel('Firing Rate')\n",
    "\n",
    "# save\n",
    "fig.savefig('../results/{}_test_response.png'.format(session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed483eb0-c49b-4e2a-870a-450e38d66831",
   "metadata": {},
   "source": [
    "# Plot Receptive Fields\n",
    "\n",
    "Now, we will look at plotting the receptive fields. First we need to get stimulus presentation data for the receptive field mapping stimulus (gabors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21cc65-29ae-465e-a321-2b71ecd8c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_field_stim_table = stimulus_presentations[stimulus_presentations['stimulus_name'].str.contains('gabor')]\n",
    "xs = np.sort(receptive_field_stim_table.position_x.unique()) #positions of gabor along azimuth\n",
    "ys = np.sort(receptive_field_stim_table.position_y.unique()) #positions of gabor along elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3bb37-55c9-409f-b564-47581f9db281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to find the receptive fields\n",
    "def find_receptive_field(spikes, xs, ys) -> np.ndarray:\n",
    "    unit_receptive_field = np.zeros([ys.size, xs.size])\n",
    "    for ix, x in enumerate(xs):\n",
    "        for iy, y in enumerate(ys):\n",
    "            stim_times = receptive_field_stim_table[(receptive_field_stim_table.position_x==x)\n",
    "                                      &(receptive_field_stim_table.position_y==y)]['start_time'].values\n",
    "            unit_response, bins = makePSTH(spikes, \n",
    "                                          stim_times+0.01, \n",
    "                                          0.2, binSize=0.001)\n",
    "            unit_receptive_field[iy, ix] = unit_response.mean()\n",
    "    return unit_receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63448677-bb8c-49c7-90dd-43e322017cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get receptive fields given any area\n",
    "def get_receptive_fields(area_of_interest:str) -> np.ndarray:\n",
    "    area_receptive_fields = []\n",
    "    area_units = good_units[good_units['structure_acronym'].str.contains(area_of_interest)]\n",
    "    \n",
    "    for iu, unit in area_units.iterrows():\n",
    "        unit_spike_times = spike_times[iu]\n",
    "        unit_receptive_field = find_receptive_field(unit_spike_times, xs, ys)\n",
    "        area_receptive_fields.append(unit_receptive_field)\n",
    "    \n",
    "    return area_receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beea747-09a1-4567-97d9-55cbdf36bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = 'VISp'\n",
    "area_receptive_fields = get_receptive_fields(area_of_interest)\n",
    "\n",
    "fig, axes = plt.subplots(int(len(area_receptive_fields)/10)+1, 10)\n",
    "fig.set_size_inches(12, 8)\n",
    "for irf, rf in enumerate(area_receptive_fields):\n",
    "    ax_row = int(irf/10)\n",
    "    ax_col = irf%10\n",
    "    axes[ax_row][ax_col].imshow(rf, origin='lower')\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd33e3-7b2c-4f19-8125-54a85a8a2c07",
   "metadata": {},
   "source": [
    "# Optotagging\n",
    "\n",
    "Let's look at the optotagging table now and plot PSTHs triggered on the laser onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8be456-c448-49de-821e-92af38a83c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "opto_table = dynamic_gating_session.optotagging_table\n",
    "time_before = 0.01 # seconds to take before the laser start for PSTH\n",
    "    \n",
    "opto_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1640f-3d15-4eef-b414-70ca3f33ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get opto response for any given probe\n",
    "def get_opto_response(probe_id:int) -> tuple[np.ndarray, ...]:\n",
    "    duration = opto_table.duration.min() #get the short pulses\n",
    "    level = opto_table.level.max() #and the high power trials\n",
    "\n",
    "    cortical_units = good_units[good_units['probe_id'] == probe_id]\n",
    "\n",
    "    opto_times = opto_table.loc[(opto_table['duration']==duration)&\n",
    "                                (opto_table['level']==level)]['start_time'].values\n",
    "    \n",
    "    duration = 0.03 # total duration of trial for PSTH in seconds\n",
    "    binSize = 0.001 # 1ms bin size for PSTH\n",
    "    \n",
    "    opto_response = []\n",
    "    unit_id = []\n",
    "    for iu, unit in cortical_units.iterrows():\n",
    "        unit_spike_times = spike_times[iu]\n",
    "        unit_response, bins = makePSTH(unit_spike_times, \n",
    "                              opto_times-time_before, duration, \n",
    "                              binSize=binSize)\n",
    "\n",
    "        opto_response.append(unit_response)\n",
    "        unit_id.append(iu)\n",
    "\n",
    "    opto_response = np.array(opto_response)\n",
    "    \n",
    "    return opto_response, bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02272be7-641b-470c-84a9-bdf81436f04b",
   "metadata": {},
   "source": [
    "We'll use the probes data from the session and look at the optotagging on a per probe basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cbc74-7715-4753-8428-fe5de8bdb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_gating_session.probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bb77a-1e00-489f-9e22-10209d6c4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = dynamic_gating_session.probes\n",
    "probe_index = 3\n",
    "\n",
    "probe_name = probes.iloc[probe_index]['name']\n",
    "probe_id = probes.index[probe_index]\n",
    "\n",
    "opto_response, bins = get_opto_response(probe_id)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((5,10))\n",
    "fig.suptitle('Optotagging: ' + str(dynamic_gating_session.metadata['ecephys_session_id'])\n",
    "             + ' ' + dynamic_gating_session.metadata['full_genotype'] + ' ' + probe_name)\n",
    "im = ax.imshow(opto_response, \n",
    "               origin='lower', aspect='auto',\n",
    "               )\n",
    "min_clim_val = 0\n",
    "max_clim_val = 250\n",
    "im.set_clim([min_clim_val, max_clim_val])    \n",
    "[ax.axvline(bound, linestyle=':', color='white', linewidth=1.0)\\\n",
    "     for bound in [10, 19]]\n",
    "ax.set_xlabel('Time from laser onset (ms)')\n",
    "ax.set_ylabel('Unit number')\n",
    "ax.set_xticks(1000*bins[:-1:5])\n",
    "\n",
    "time_labels = np.round(1000*(bins[:-1:5]-time_before), 0)\n",
    "_=ax.set_xticklabels(time_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60acc7-7e4e-4de3-b0ee-a60a722ffc44",
   "metadata": {},
   "source": [
    "Let's plot the response to the laser over the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9f6d6-2fc8-4f15-85a7-f4c0b4b8c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_window = slice(0, 9)  # baseline epoch\n",
    "response_window = slice(11,18) # laser epoch\n",
    "\n",
    "response_magnitudes = np.mean(opto_response[:, response_window], axis=1) \\\n",
    "                    - np.mean(opto_response[:, baseline_window], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e429f8b-6fa1-48cb-b608-a66ab8ea4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "# Plot scatter of opto rate vs baseline rate\n",
    "axes[0].plot(np.mean(opto_response[:, baseline_window], axis=1),\n",
    "         np.mean(opto_response[:, response_window], axis=1), 'k.', alpha=0.2)\n",
    "axes[0].set_xlim([-10, 200])\n",
    "axes[0].set_ylim([-10, 400])\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_ylabel('response rate (Hz)')\n",
    "axes[0].set_xlabel('baseline rate (Hz)')\n",
    "\n",
    "# Plot histogram of opto-evoked rate (note log yscale)\n",
    "_ = axes[1].hist(response_magnitudes, bins=20)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Opto-evoked rate (Hz)')\n",
    "axes[1].set_ylabel('Unit Count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
